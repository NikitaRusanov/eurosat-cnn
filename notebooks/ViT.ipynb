{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfCxjGV5oTiJ"
      },
      "source": [
        "# Vit Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "D-FMYv-jwLiV"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbFQzHV6k59K"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "d4208U17s4ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([260, 255, 270, 260, 265, 270, 260, 255, 265, 260])\n",
        "a = np.mean((a - a.mean())**2)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB3pai8mtGqQ",
        "outputId": "2f5334df-b9b5-4abc-e155-9959d59044e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(26.0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2103Lz4tR31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3hL_6WoCwLiX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVgNwDyzwLiY",
        "outputId": "559317dd-2155-4123-9a5b-ff7ccc5b8ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 10])\n",
            "tensor([[-0.1438,  2.2744, -0.9172, -1.0377, -1.3586,  2.1810, -0.2296,  0.1823,\n",
            "         -0.6359,  0.3380],\n",
            "        [-0.8870, -0.7761,  0.3335, -0.1858, -0.5488, -0.2779, -0.5234, -1.0582,\n",
            "         -0.6237,  1.0140],\n",
            "        [-0.7232, -1.3026,  1.1943,  0.4699, -1.8754, -1.2094, -0.6722, -1.0889,\n",
            "         -0.9344,  0.7425],\n",
            "        [-0.2837,  1.7002, -1.7405,  0.5689, -0.2981,  0.1050,  0.6209,  0.4541,\n",
            "         -0.8066,  0.5574],\n",
            "        [ 1.0143, -1.4575, -0.3882, -0.7326,  0.4771, -1.2785,  0.1737, -0.2157,\n",
            "         -0.2094,  0.5685]])\n"
          ]
        }
      ],
      "source": [
        "# Смоделируем данные\n",
        "\n",
        "n_features = 10  # Количество признаков\n",
        "n_classes = 3  # Количество классов\n",
        "batch_size = 5\n",
        "\n",
        "data = torch.randn((batch_size, n_features))\n",
        "print(data.shape)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKVgvWaawLiZ"
      },
      "outputs": [],
      "source": [
        "# Зададим простую модель\n",
        "model = nn.Linear(n_features, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyfujdNcwLia",
        "outputId": "ede85679-e1bc-4879-d0c6-f8887b5d594b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[-0.3339,  0.2168,  0.4533],\n",
            "        [ 1.2266, -0.3086, -0.1748],\n",
            "        [ 0.3546, -0.1696,  0.3773],\n",
            "        [ 0.7408, -0.5658, -0.0895],\n",
            "        [-0.2664,  0.1234,  0.1510]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Применим модель к вектору\n",
        "answer = model(data)\n",
        "print(answer.shape)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCsGwzuRwLib"
      },
      "outputs": [],
      "source": [
        "# Модель как наследник nn.Module\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, n_features, n_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin = nn.Linear(n_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJvKzV5ewLic",
        "outputId": "54046c51-d9c0-4455-cc6c-cc6fc9a16a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[-0.8417,  0.1221,  0.2182],\n",
            "        [-0.5111,  0.4327, -0.0301],\n",
            "        [-0.5966, -0.0424,  0.2316],\n",
            "        [ 0.3835, -0.7634,  0.1471],\n",
            "        [-0.4673,  1.1093,  0.1214]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Попробуем применить модель в виде класса к данным\n",
        "model = SimpleNN(n_features, n_classes)\n",
        "\n",
        "answer = model(data)\n",
        "print(answer.shape)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I-SqCkrwLid",
        "outputId": "edbaafc3-ac72-4fd4-c54e-924bca4ff667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 5, 3]              33\n",
            "================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "model = SimpleNN(n_features, n_classes).cuda()\n",
        "\n",
        "# 5, 10\n",
        "input_size = (batch_size, n_features)\n",
        "print(summary(model, input_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIBvYYBewLie",
        "outputId": "b6cf7c37-c081-4ff4-9a92-567be769f873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[ 0.6964,  1.1708,  0.2012],\n",
            "        [-1.0536,  0.1585,  0.6737],\n",
            "        [-0.1184, -1.1487, -0.7225],\n",
            "        [-0.1362, -0.1379,  0.5185],\n",
            "        [-0.5427, -0.1601,  0.0570]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Модель как sequential\n",
        "model = nn.Sequential(nn.Linear(n_features, n_classes))\n",
        "\n",
        "answer = model(data)\n",
        "print(answer.shape)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBwzYlptwLif",
        "outputId": "14574dc5-d9c3-4b70-881d-267b3893571c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[ 0.5566,  0.1300,  0.5891],\n",
            "        [-0.2395, -1.0017, -0.4804],\n",
            "        [-0.5754, -0.1751, -0.1344],\n",
            "        [-0.2375, -0.5495,  0.0195],\n",
            "        [ 0.7670,  0.3696, -0.3767]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Модель как nn.ModuleList\n",
        "\n",
        "model = nn.ModuleList([nn.Linear(n_features, n_classes)])\n",
        "\n",
        "# answer = model(data)\n",
        "# print(answer.shape)\n",
        "# print(answer)\n",
        "\n",
        "answer = model[0](data)\n",
        "print(answer.shape)\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5fE17SRwLig"
      },
      "outputs": [],
      "source": [
        "# Проверим параметры модели\n",
        "class ParametersCheck(nn.Module):\n",
        "    def __init__(self, n_features, n_classes):\n",
        "        super().__init__()\n",
        "        self.sdfasdf = nn.Parameter()\n",
        "\n",
        "        self.lin = nn.Linear(n_features, n_classes)\n",
        "        self.seq = nn.Sequential(nn.Linear(n_features, n_classes))\n",
        "        self.module_list = nn.ModuleList([nn.Linear(n_features, n_classes)])\n",
        "        self.list_of_layers = [nn.Linear(n_features, n_classes)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzvFgyhHwLih",
        "outputId": "a34a2799-f3e0-4aa8-93b1-68f8946f3cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Параметр #1.\n",
            "\ttorch.Size([0])\n",
            "Параметр #2.\n",
            "\ttorch.Size([3, 10])\n",
            "Параметр #3.\n",
            "\ttorch.Size([3])\n",
            "Параметр #4.\n",
            "\ttorch.Size([3, 10])\n",
            "Параметр #5.\n",
            "\ttorch.Size([3])\n",
            "Параметр #6.\n",
            "\ttorch.Size([3, 10])\n",
            "Параметр #7.\n",
            "\ttorch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "model = ParametersCheck(n_features, n_classes)\n",
        "\n",
        "for i, param in enumerate(model.parameters()):\n",
        "    print(f'Параметр #{i + 1}.')\n",
        "    print(f'\\t{param.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9_ccpqgpwLih"
      },
      "source": [
        "## ViT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "O9Ck2xnvwLii"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1J5TvycDPs8pzfvlXvtO5MCFBy64yp9Fa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFzQd5YDEbas",
        "outputId": "90dbf174-c343-4383-c966-17ced8f3e4e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khe7vy_ZwLii"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbPI9vsXDZH9"
      },
      "source": [
        "![](https://amaarora.github.io/images/vit-01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDDoMou3RKSy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Au2Fd1FZbj"
      },
      "source": [
        "## Часть 1. Patch Embedding, CLS Token, Position Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjbKwA7lGY3O"
      },
      "source": [
        "![](https://amaarora.github.io/images/vit-02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tH4Nb22GeuS",
        "outputId": "b0463d60-e5e2-4933-80c0-740568ea6669"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([196, 768])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input image `B, C, H, W`\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "# 2D conv\n",
        "conv = nn.Conv2d(3, 768, 16, 16)\n",
        "conv(x).reshape(-1, 196).transpose(0,1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVwf4n1bwLik"
      },
      "outputs": [],
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size: int=224, patch_size: int=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        self.patch_num = (img_size // patch_size)**2\n",
        "        img_size = (img_size, img_size)\n",
        "        patch_size = (patch_size, patch_size)\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Conv2d(in_chans, embed_dim, patch_size, patch_size),\n",
        "\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn((1, embed_dim)))\n",
        "        self.positions = nn.Parameter(torch.randn((self.patch_num + 1, embed_dim)))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # проверка на размер изображения\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        x = self.projection(x).view(b, self.patch_num, -1)\n",
        "        t = self.cls_token.expand(b, -1, -1)\n",
        "        x = torch.cat((t, x), 1)\n",
        "        print(x[0, 0] == self.cls_token)\n",
        "        x = x + self.positions\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E57UzPBuE4qi",
        "outputId": "4717668a-b2ff-4b09-df3d-61cbed64cf10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "         True, True, True, True, True, True, True, True, True, True, True, True]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 197, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "patch_embed = PatchEmbedding()\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "patch_embed(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVUm-TJFGm6L"
      },
      "source": [
        "![](https://amaarora.github.io/images/vit-03.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUxuB53PFv1h"
      },
      "source": [
        "## Часть 2. Transformer Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkklM-fqFpa9"
      },
      "source": [
        "![](https://amaarora.github.io/images/ViT.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G34WzminccX7"
      },
      "source": [
        "![](https://amaarora.github.io/images/vit-07.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACAqbCivDGsa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPQts2WWdeYQ"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        # Linear Layers\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFxxcPoMf7IW",
        "outputId": "0b6996da-1762-467d-e6a5-b520b193f726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 197, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x = torch.randn(1, 197,768)\n",
        "mlp = MLP(768, 3072, 768)\n",
        "out = mlp(x)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QnAW3rSc2OZ"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim=768, num_heads=8, qkv_bias=False, attn_drop=0., out_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, 3 * dim)\n",
        "        self.attn_drop = nn.Dropout(p=attn_drop)\n",
        "        self.out = nn.Linear(dim, dim)\n",
        "        self.out_drop = nn.Dropout(p=out_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b, h, w = x.shape\n",
        "\n",
        "        # Attention\n",
        "        qkv = self.qkv(x).reshape(b, h, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = F.softmax((q @ k.transpose(-2, -1)) * self.scale, dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "        x = (attn @ v).transpose(1, 2).reshape(b, h, w)\n",
        "        # Out projection\n",
        "        x = self.out(x)\n",
        "        x = self.out_drop(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_vgvLDbcjvi"
      },
      "source": [
        "![](https://amaarora.github.io/images/vit-08.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OukFkeXzdFpB"
      },
      "outputs": [],
      "source": [
        "# attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "# attn = attn.softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NeRHHJAgg5R",
        "outputId": "b7e12ede-676e-43a2-c325-a284ce55047f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-fdc9b4342685>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = F.softmax((q @ k) * self.scale)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 197, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x = torch.randn(1, 197, 768)\n",
        "attention = Attention(768, 8)\n",
        "out = attention(x)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6e8y_YvwLik"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, mlp_ratio=4, drop_rate=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        # Normalization\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "        # Attention\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "\n",
        "        # Dropout\n",
        "\n",
        "\n",
        "        # MLP\n",
        "        self.mlp = MLP(768, 3072)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Attetnion\n",
        "        x = self.attn(self.norm1(x)) + x\n",
        "\n",
        "        # MLP\n",
        "        x = self.mlp(self.norm2(x)) + x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aMihgfEhyql",
        "outputId": "0f9555cb-223c-4652-a31a-24dcc4db1577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-fdc9b4342685>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = F.softmax((q @ k) * self.scale)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 197, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x = torch.randn(1, 197, 768)\n",
        "block = Block(768, 8)\n",
        "out = attention(x)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPBmiO5FhoN6"
      },
      "source": [
        "В оригинальной реализации теперь используется [DropPath](https://github.com/rwightman/pytorch-image-models/blob/e98c93264cde1657b188f974dc928b9d73303b18/timm/layers/drop.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1uO18VTwLil"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, depth, dim, num_heads=8, mlp_ratio=4, drop_rate=0.):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(dim, num_heads, mlp_ratio, drop_rate)\n",
        "            for i in range(depth)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIfp984oiBqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d79e3e-a507-4263-d935-31cca46c9c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-fdc9b4342685>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = F.softmax((q @ k) * self.scale)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x = torch.randn(2, 197, 768)\n",
        "block = Transformer(12, 768)\n",
        "out = attention(x)[:, 0]\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqUxpyv3cwNm"
      },
      "source": [
        "![](https://amaarora.github.io/images/vit-06.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9gyxdqQeFs6"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.normalization import LayerNorm\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000,\n",
        "                 embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.,\n",
        "                 qkv_bias=False, drop_rate=0.,):\n",
        "        super().__init__()\n",
        "\n",
        "        # Присвоение переменных\n",
        "\n",
        "        # Path Embeddings, CLS Token, Position Encoding\n",
        "        self.embedings = PatchEmbedding(img_size, patch_size, in_chans, embed_dim)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        self.transformer = Transformer(depth, embed_dim, num_heads)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Path Embeddings, CLS Token, Position Encoding\n",
        "        x = self.embedings(x)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Classifier\n",
        "        x = self.classifier(x[:, 0])\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lGhne8kjeYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b69d47-4a47-4246-dd48-fb099eb3a9b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-fdc9b4342685>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = F.softmax((q @ k) * self.scale)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "x = torch.randn(1, 3, 224, 224)\n",
        "vit = ViT()\n",
        "out = vit(x)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QbFtayBkp-c"
      },
      "source": [
        "# Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nZbwbK9kskc"
      },
      "source": [
        "\n",
        "1. Выбрать датасет для классификации изображений с размерностью 64x64+\n",
        "2. Обучить ViT на таком датасете.\n",
        "3. Попробовать поменять размерности и посмотреть, что поменяется при обучении.\n",
        "\n",
        "\n",
        "Примечание:\n",
        "- Датасеты можно взять [тут](https://pytorch.org/vision/stable/datasets.html#built-in-datasets) или найти в другом месте.\n",
        "- Из за того, что ViT учится медленно, количество примеров в датасете можно ограничить до 1к-5к."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}